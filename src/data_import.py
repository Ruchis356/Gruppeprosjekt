# Possible improvement: Use lists to append data before making a dataframe rather than "appending" to an empty dataframe



import requests
import pandas as pd
import numpy as np

#A class to import and handle environmental data (weather and air quality)
class RawData:

    #Initialize the EnvironmentalData class
    def __init__(self):
        self.df = None

    # ------------------------------------------
    # WEATHER DATA - IMPORT
    # ------------------------------------------

    #Fetch weather data from the Frost API 
    def get_met(self, weather_station, weather_elements, weather_time, weather_resolution):

        """
        Fetch weather data from the Frost API.

        Args:
            weather_station (str): The ID of the weather station.
            weather_elements (str): The measurements to include.
            weather_time (str): The time range for the data.
            weather_resolution (str): The granularity of the data.

        Returns:
            pd.DataFrame: A DataFrame containing the weather data.
                Returns None if an error occurs.
        """        

        try:

            # The following block of code (if statements) was mainly generated by AI, lightly reworked
            # - Purpose: Raise an error if the given arguments are invalid
            # - AI tool: DeepSeek

            # Validate the arguments given to the function
            if not weather_station or not weather_elements or not weather_time or not weather_resolution:
                raise ValueError("All input parameters must be provided.")

            if not isinstance(weather_station, str):
                raise ValueError("weather_station must be a string.")

            if not isinstance(weather_elements, str):
                raise ValueError("weather_elements must be a string.")

            if not isinstance(weather_time, str):
                raise ValueError("weather_time must be a string.")

            if not isinstance(weather_resolution, str):
                raise ValueError("weather_resolution must be a string.")

            # If the arguments are valid, proceed with the API request

            # Client ID to access data from Frost API
            client_id = 'd933f861-70f3-4d0f-adc6-b1edb5978a9e'

            # The following block of code (the four variable lines) was generated with the assistance of AI
            # - Purpose: Correctly call upon the four variables in this function
            # - AI tool: DeepSeek

            # Define endpoints and parameters
            endpoint = 'https://frost.met.no/observations/v0.jsonld'
            parameters = {
                'sources': weather_station,  # Station ID for Voll weather station
                'elements': weather_elements,  # Requestion various types of eather data
                'referencetime': weather_time,  # Limiting the time frame for the data request
                'timeresolutions': weather_resolution,  # Set the resolution(granularity) of the data
            }

            # Send an HTTP GET-request
            response = requests.get(endpoint, params=parameters, auth=(client_id, ''))

            # Extract JSON-data
            json_data = response.json()

            # Check if the request was succesfull, and exit if not
            if response.status_code == 200:
                data = json_data['data']
                print('Data collected from frost.met.no!')
            else:
                print('Error! Statuscode:', response.status_code)
                print('Message:', json_data['error']['message'])
                print('Cause:', json_data['error']['reason'])
                return None

            # Create and set up the dataframe
            data_list = []
            for obs in data:
                if isinstance(obs['observations'], list):
                    for observation in obs['observations']:
                        row = observation.copy()
                        row['referenceTime'] = obs['referenceTime']
                        data_list.append(row)
                else:
                    row = obs['observations'].copy()
                    row['referenceTime'] = obs['referenceTime']
                    data_list.append(row)
            df = pd.DataFrame(data_list)

            # Remove uneeded collumns  

            '''add timeoffset if we decide not to use it: , "timeOffset"'''

            columns_to_drop = ["level", "timeResolution", "timeSeriesId", "elementId", "performanceCategory", "exposureCategory", "qualityCode"]
            df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])

            # Remove time portion from 'referenceTime' (keep only 'YYYY-MM-DD')
            df["referenceTime"] = df["referenceTime"].str.split("T").str[0]

            print('There are ', df.shape[0]-1, 'lines of data in this dataframe.\n')
            self.df = df

            #Returns dataframe upon request
            return(df)
        
        # The following block was generated with the assistance of AI
        # Purpose: Including more specific errors; Connection, timeout, and HTTP
        # AI tool: DeepSeek

        # Return an error code if fetching the weather data fails
        except ValueError as e:
            print(f"Invalid input: {e}")
            return None
        except requests.exceptions.ConnectionError:
            print("Error: Failed to connect to the Frost API. Check your internet connection.")
            return None
        except requests.exceptions.Timeout:
            print("Error: The request to the Frost API timed out. Please try again later.")
            return None
        except requests.exceptions.HTTPError as e:
            print(f"Error: The Frost API returned an HTTP error: {e}")
            return None
        except Exception as e:
            print(f"An unexpected error has occured: {e}")
            return None


    # ------------------------------------------
    # AIR QUALITY DATA - IMPORT
    # ------------------------------------------

    # Fetch air quality data by Nilu from a CSV file
    def get_nilu(self, threshold, file_path): 

        """
        Args:
            file_path (str): Path to the CSV file.
            threshold (float): Threshold for coverage values.

        Returns:
            pd.DataFrame: A DataFrame containing the air quality data.
        """

        # The following block was optimised for lower resource use with the assistance of AI
        # Purpose: reduce runtime and improve of the code
        # AI tool: DeepSeek

        try:
            # parsing csv file
            df = pd.read_csv(
                file_path,
                skiprows=3,
                sep=';',
                on_bad_lines='skip',
                encoding='utf-8',
                parse_dates=['Tid'],
                date_format='%d.%m.%Y %H:%M',
                na_values='',  # Replace empty strings with NaN
                decimal=',',   # Handle comma decimals correctly
                dtype={col: 'float64' for col in pd.read_csv(file_path, nrows=1, skiprows=3, sep=';').columns 
                    if col != 'Tid'}  # Pre-specify dtypes
            )
            
            # Replace the coverage(uptime) values that fall below the treshold with 0, to exclude the data from analysis
            columns_coverage = df.columns[df.columns.str.contains('Dekning', case=False, regex=True)].tolist()
            for col in columns_coverage:
                mask = df[col] < threshold
                df.loc[mask, col] = 0
                
                # Replace the air quality data with NaN where the coverage is too poor
                left_col_index = df.columns.get_loc(col) - 1
                if left_col_index >= 0:
                    left_col = df.columns[left_col_index]
                    df.loc[mask, left_col] = np.nan
            
            # Print diagnostics
            print('Data collected from nilu.com!')
            print(f'There are {df.shape[0]} lines of data in this dataframe.\n')
            self.df = df
            
            # Return the dataframe
            return df
        
        # The following block was generated with the assistance of AI
        # Purpose: Including more specific errors; FileNotFound, ParserError
        # AI tool: DeepSeek

        # Return an error code if reading the csv file failed
        except FileNotFoundError:
            print(f"Error: The file '{file_path}' was not found. Check the file path.")
            return None
        except pd.errors.ParserError:
            print("Error: Could not read the csv file. Check the formatting and encoding.")
            return None
        except Exception as e:
            print(f"An unexpected error has occured: {e}")
            return None

