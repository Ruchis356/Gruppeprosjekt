**Deepseek:** 
README.md (main readme)
    - AI suggested some structure and to include certain sections in the main readme file. 
    - Including Project setup, Project structure, and expected irregularities was suggested by AI.
    - 'Project setup' was mainly generated by AI and only lightly reworked.
requirements.txt
    - 

README.md (notebooks readme)
    - The file was fully formatted by AI.
    - The tables were generated by AI. 
    - AI suggested includng certain sections, like 'Usage tips'
main.ipynb
    - minor changes to sys.path.insert were suggested by AI, to improve the import from the file structure.
    - AI generated the construct for fetching todays date.
    - Using path/PathLib was suggested by AI.
    - AI generated a block of code to supply temporary weather data when the API was down (defunct).
    - AI suggested including a 'strategy' variable, to enable easy shifts between different ways of handling missing data.
    - AI generated a codeblock for EDA of the main sections for importing and the initially handling data. In order to give us, as programmers, an understanding of what the dataframes look like (defunct).
    - The helper function for displaying tables in the 'Data and pattern analysis' section was initially generated by AI and further refined by the developer. 
    - In the section for creating and training models, AI was used to generate a block of code to check for missing features for the pollutant currently being made a model of.
    - The block of code that summarises a performance report for the trained pollution variable models was generated by AI.
    - AI suggested a helper function to create the tables of the worst predictions made by each model. AI was also used to refine this function to be as smooth as it could be.
    - The saving data to file section was written with assistance from AI. Speifically, writing the correct location for the file to be saved to. The codeblock that saves the pollution forecast was largely generated by AI.

README.md (src readme)
    - The whole file was formatted by AI.
    - AI was also used for spellcheck, feedback, and general suggestions. 
data_import.py
    - The block of repetative if - error statements at the beginning of the get_met function was generated by AI, and edited down a bit. 
    - AI was used to correct the implementation of variables in the get_met function, as it was throwing up a TypeError. The parameter setup for the API function was generated with assistance from AI in order to correctly call upon the four variables.
    - AI generated the df.drop_duplicates construct and suggested how to use df.pivot to improve a block of code.
    - AI was used to suggest more specific error messages for the import functions, namely invalid arguments, connection error, timeout error, HTTP error, File not found, and parsing error.
   - AI helped optimize for lower resource use by using of pd.read_csv().
    - AI suggested and helped develop the two blocks of code dealing with coverage, enabling the removal of an entire function in data_handling.
    - In the forecast function Ai suggested improvements for more robust datetime handling.
    - AI suggested how to make the get_nilu function less hardcoded, by searching for columns that contain the string 'dekning' rather than naming each column individually.
    - When replacing values with too poor coverage, it was a suggestion from AI to check if the "column to the left" exists.
data_handling.py
    - AI suggested adding the arguments 'strategy' and 'fill_value' to the missing_data function. 
    - AI suggested and generated a block of code for taking strategy into account when dealing with missing values.
    - The use of df.isna() was suggested by AI to check for missing values.
    - The method for finding the coverage columns was copied from data_import.py and used in the same way.
    - AI generated the following construct: df.index[df[col] == 0].tolist()
    - The correct formatting of this construct was assisted by AI: zero_locations.append({'index': index, 'column': col})
    - Including input validation was suggested by AI.
utils.py
    - The creation of this file, to contain the display table function, was suggested by AI.
    - Improvements to the function pretty_data was assisted by AI, to make displayed tables scrollable.
    - The construct for reformatting the datetime format was generated by AI.
    - The conditional import for Jupyter was suggested and generated by AI.
    - Reformatting datetime to show only the dates in the printed table was generated by AI.
analysis.py
    - The main block of code for calculating the average(mean) was improved by AI through vectorisation.
    - The main block of code for calculating the standard deviation was improved by AI through vectorisation.
    - Input validation for the outliers function was generated by AI.
    - Error handling for the outliers function was generated by AI.
    - Data validation for the box plot function was generated by AI.
predictive_analysis.py
    - In the function for loading and merging data AI generated a block of code to gracefully handle missing columns.
    - Several logger functions were generated by AI in order to provide detailed information about the model and its data.
    - The block of code creating the features from ineracting weather variables was generated by AI.
    - The section for generating all the features was expanded by AI to reduce manually typing them out.
    - A block of code creating the columns spike indicator and wind speed change was generated by AI to see if it would help with developing the model. They did not. (defunct)
    - The helper function safe_fit was mainly generated by AI to safely deal with NaN values. 
    - The default features for train_model were developed with the assistance of AI.
    - Input validation for evaluate_model was partially generated by AI. 
    - Creating explicit copies with .copy() to avoid SettingWithCopyWarning was suggested AI, for evaluate_model.
    - Several Random Forest configuration suggestions from AI were used.
    - Parameter validation for forecast_pollutants_with_lags was generated by AI. And the recursive prediction loop structure was refined with DeepSeek.
    - The DayOfYear_sin/cos seasonal features were a DeepSeek optimization.
graphs.py
    - AI suggested setting a general theme for the class and generated the relevant code.
    - The construct sns.scatterplot for the dot_graph function was generated by AI.
    - AI contributed much assistance to align the origin of both y-axis in the twinx plots. One block specifically for solving this problem was generated by AI.
    - AI generated the construct for colour in the comparative graph function. 
    - Most input validations were partially generated by AI.
graph_test.py
    - InteractiveGraphs class was developed with AI assistance for Plotly implementation, particularly for toggle button functionality
    - The dotted graph function was developed with significant assitance from AI, especially when encountering a series of challenging errors.
    - The comparative has been through AI multiple times, as we never managed to find the correct solution for it to work as intended. Because of this, at this point it's unclear what was done by the AI and what was done by the developer.

README.md (test readme)
    - 
    - 
test_data_import.py
    - minor changes to sys.path.insert were suggested by AI, to improve the import from the file structure.
    - Using patch and Mock from unittest.mock was suggested by AI.
    - Creating a mock API response that functions as expected was assisted by AI, which was used at multiple points in the code.
    - Testing the handling of invalid inputs was suggested by AI.
    - minor changes to sys.path.insert were suggested by AI, to improve the import from the file structure.
    - Creating a mock CSV file that functions as expected was assisted by AI.
    - Including an assertion for the function of removing poor quality data was suggested by AI.
    - AI generated this construct: os.remove('test_nilu.csv')
    - Testing for file not found handling was suggested by AI.
    - AI generated the line: f.write("Tid;Dekning\n01.10.2023 00:00;100\ninvalid_line")
test_data_handling.py
    - AI was used to proofread the code.

test_analysis.py
    - AI assisted in pinpointing errors and solving possible problems.
    - AI proofread the code.
test_data_handling.py
    - 
    -

test_predictive_analysis.py
    - 
    - 
    

General/no file
    - AI was semi-regularly used for more accurately interpreting error codes and to pinpoint what problems needed to be solved, as well as suggesting different ways of handling errors and how to improve error handling in general.
    - AI was used to proofread several sections of code, and to give general feedback. If the feedback was used it has been noted here and in the code. 
    - The header style used in all code files was suggested by AI. 
    - AI suggested various formats for AI disclosure within the code.
    - The use of logging and logging infrastructure was suggested by AI, and many of the more complex logging constructs we initially generated by AI and then reworked for the code.
    - AI has been used to consistently format docstring and improve wording. 
    - Including __all__ at the beginning of each python file was suggested by AI.

**ChatGPT:** 
README (src):
    - Structure and format has been suggested by the use of AI 
    - Phrasing and definitions have been suggested by AI
README (notebooks): 
    - Grammar and punctuation has been enhanced by the use of AI
analysis.py:
    - AI suggested efficient ways of calculating weekly data, by taking into consideration of weeks with missing data, by using the df_week.dropna() and avg_value = df_clean.mean() code line, such that weekly averages were costumized for their available data values. 
    - Use of AI was implemented to suggest ways of importing air quality data as file paths and storing these as data frames using the "with open(file_path, 'r', encoding='utf-8') as file:" codeline
    - AI was used to test and fix any error messages regaridng the boxplot diagrams, and suggesting ways of making graphs more visually pleasing 
    - AI suggested a way of using the average function on multiple pollutants by using the codeline " weekly_avg_table = build_weekly_avg_table(df_air, pollutants)"
    - Use of AI was implemented to add calcualted outlier values to the exisitng data frames
test_data_handling.py
    - AI was used to teach developer how to write unit tests, explaining the main structure of Arrange Act and Assert. 
    - AI was used to suggest improvements in the code by suggesting the use of "self.processor" and "self.processor = RefinedData()" code which acted as a gateway to call on all of the funcions inside the data_handling files
    - AI helped organize the code into a better format and suggested any errors/problems in the code
    - AI helped suggest a sample test data frame (self.df) as an appropriate data frame that could be used to test all of the funcitons inside data_handling




test_predicitive_analysis.py

    -AI was used to teach developers proper testing approaches for machine learning models, including how to validate RandomForest predictions and handle edge cases.
    -AI contributed the mutual information feature selection approach that automatically identifies the most relevant weather features for pollution prediction during testing.
    -AI suggested the safe_fit() implementation that makes model training more robust by properly handling NaN values in test data.




test_analysis.py
    - AI suggested the use of Error handling and assertions like assertIsInstance, assertAlmostEqual, and assertRaises to validate behaviour of the functions
    - AI was used to fix any error codes during the unit tests 
    - AI was used to write code for total_average and standard_deviation entirely, due to challenging factor of testing the function
    - AI was used to check to see if I the code were able to cover all types errors that could be caused by the functions ()
test_predicitive_analysis.py
    -AI was used to teach developers proper testing approaches for machine learning models, including how to validate RandomForest predictions and handle edge cases.
    -AI contributed the mutual information feature selection approach that automatically identifies the most relevant weather features for pollution prediction during testing.
    -AI suggested the safe_fit() implementation that makes model training more robust by properly handling NaN values in test data.
General/no file
    - AI was semi-regularly used for more accurately interpreting error codes and to pinpoint what problems needed to be solved, as well as suggesting different ways of handling errors and how to improve error handling in general.
    - AI was used to proofread several sections of code, and to give general feedback. If the feedback was used it has been noted here and in the code. 
    - AI suggested various formats for AI disclosure within the code.